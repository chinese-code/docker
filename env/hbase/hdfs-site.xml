<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->
<configuration>
<!--副本数量-->
<property>
<name>dfs.replication</name>
<value>3</value>
</property>
<!--block数据在dataNode中的存储位置-->
<property>
<name>dfs.datanode.data.dir</name>
<value>/hadoop/hdfs/data</value>
</property>
<!--block数据块默认大小-->
<property>
<name>dfs.blocksize</name>
<value>8m</value>
</property>
<!--namenode最多用多少个线程处理来自dataNode的请求-->
<property>
<name>dfs.namenode.handler.count</name>
<value>10</value>
</property>
<!--配置集群名称-->
<property>
<name>dfs.nameservices</name>
<value>hadoopcluster</value>
</property>
<!--配置集群namenode列表-->
<property>
  <name>dfs.ha.namenodes.hadoopcluster</name>
  <value>namenode1,namenode2</value>
</property>
<!--namenode的RPC监听端口-->
<property>
  <name>dfs.namenode.rpc-address.hadoopcluster.namenode1</name>
  <value>cluster.namenode1.server:8020</value>
</property>
<property>
  <name>dfs.namenode.rpc-address.hadoopcluster.namenode2</name>
  <value>cluster.namenode2.server:8020</value>
</property>
<!--namenode的http监听端口-->
<property>
  <name>dfs.namenode.http-address.hadoopcluster.namenode1</name>
  <value>cluster.namenode1.server:50070</value>
</property>
<property>
  <name>dfs.namenode.http-address.hadoopcluster.namenode2</name>
  <value>cluster.namenode2.server:50070</value>
</property>
<!--journalnode列表-->
<property>
  <name>dfs.namenode.shared.edits.dir</name>
  <value>qjournal://cluster.journalnode1.server:8485;cluster.journalnode2.server:8485;cluster.journalnode3.server:8485/hadoopcluster</value>
</property>
<!--当active namenode宕机时.该类可以返回一个新的strandy节点-->
<property>
  <name>dfs.client.failover.proxy.provider.hadoopcluster</name>
  <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<!--active namenode出错时的处理方法-->
<property>
  <name>dfs.ha.fencing.methods</name>
  <value>shell(/bin/true)</value>
</property>
<!--
<property>
  <name>dfs.ha.fencing.methods</name>
  <value>sshfence</value>
</property>
<property>
-->
<!--配置为sshfence时，还需要配置SSH-->
<!--
<name>dfs.ha.fencing.ssh.private-key-files</name>
 <value>/root/.ssh/id_rsa</value>
</property>
-->
<!--用于journalnode同步的edits日志目录-->
<property>
  <name>dfs.journalnode.edits.dir</name>
  <value>/hadoop/journal-edits-data</value>
</property>
<!--允许namenode宕机时，自动切换到其他namenode-->
 <property>
   <name>dfs.ha.automatic-failover.enabled</name>
   <value>true</value>
 </property>
</configuration>
